# AlphaForge Brain – Deterministic Single-User Trading Lab Backend

<div align="right">

**Jump To:** [Hello Run](#hello-run-quickstart) · [Architecture](#3-high-level-architecture) · [API Guide](#9-api-guide-practical-quickstart) · [Retention](#15-retention-enhancements-cold-storage-offload-restore--plan-diff) · [Extensibility](#13-extensibility-guide)

</div>

<!-- TOC START (generated by scripts/docs/generate_readme_toc.py) -->
- [AlphaForge Brain – Deterministic Single-User Trading Lab Backend](#alphaforge-brain-deterministic-single-user-trading-lab-backend)
<!-- TOC END -->

![Version (Static)](https://img.shields.io/badge/version-0.3.0-blue.svg) ![Version (Dynamic)](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/friscapuff/AlphaForge-Brain/badges/version_badge.json) ![Upcoming](https://img.shields.io/badge/unreleased-0.3.1--dev-orange.svg) ![Python](https://img.shields.io/badge/python-3.11.x-blue.svg) ![Coverage](https://img.shields.io/badge/coverage-available%20in%20CI-lightgrey.svg) ![License](https://img.shields.io/badge/license-MIT-green.svg) ![Benchmarks](https://img.shields.io/badge/bench-risk_slippage%20&%20perf_run-informational.svg) ![Typing](https://img.shields.io/badge/typing-mypy--strict-success.svg)

AlphaForge Brain is a deterministic, modular backend for running strategy backtests, risk-adjusted simulations, and statistical validations. It targets a single power user who wants **repeatable experiments**, **artifact integrity**, and **low-friction iteration** without premature multi-user overhead. A future UI (out of scope here) will sit on top of these APIs. The codebase has recently completed a full **strict typing & lint hardening phase** (upcoming v0.3.0) and now exposes multi-symbol abstractions preparing for future portfolio-level extensions.

## Quick Start: Launch AlphaForge (Backend + UI)

You can start both the backend API and the Mind UI with one command. This opens the UI in your browser so you can explore charts and run backtests immediately.

### One-Time Setup
1. Install Python 3.11 and Node.js (≥18).
2. Install backend deps (run in repo root):
  ```powershell
  poetry install
  ```
3. Install frontend deps:
  ```powershell
  cd alphaforge-mind
  npm install
  cd ..
  ```

### Launch (Single Command)
```powershell
poetry run launch-alphaforge
```

What happens:
* Backend starts at http://127.0.0.1:8000  (API docs at /docs)
* Frontend (Vite) starts at http://127.0.0.1:5173
* Your default browser opens automatically (if possible)

Press Ctrl+C once to stop both.

### New CLI Flags (Unified Launch Feature)
Specification: `specs/007-unified-one-command/spec.md`.

| Flag | Purpose | Default |
|------|---------|---------|
| `--backend-port <int>` | Override backend API port | 8000 |
| `--frontend-port <int>` | Preferred frontend dev port (auto-fallback upward if busy) | 5173 |
| `--timeout <seconds>` | Readiness timeout window | 45 |
| `--no-browser` | Suppress auto browser open (headless / CI) | off |
| `-v` / `--verbose` | Extra diagnostics (npm path, chosen ports, probe attempts) | off |
| `-q` / `--quiet` | Minimal output (hide spinners & ready banners) | off |

Examples:
```powershell
poetry run launch-alphaforge --backend-port 8100 --frontend-port 5200 -v
poetry run launch-alphaforge --no-browser
poetry run launch-alphaforge -q
```

Behavior Notes:
* Port Fallback: If preferred frontend port is taken, launcher scans next 15 ports.
* Readiness: Requires both TCP port and HTTP probe success (`/health` backend, root page frontend).
* Graceful Shutdown: Single Ctrl+C terminates both processes cleanly.
* Diagnostics: Verbose mode includes timestamps & detection events; quiet mode prints only final URLs or errors.

### Windows Double-Click Option
```powershell
./launch-alphaforge.ps1
```
If PowerShell blocks the script:
```powershell
Set-ExecutionPolicy -Scope CurrentUser -ExecutionPolicy RemoteSigned
```

### Troubleshooting
| Issue | Action |
|-------|--------|
| Browser didn’t open | Manually visit http://127.0.0.1:5173 |
| 'npm' not found | Install Node.js https://nodejs.org/ then run npm install in alphaforge-mind |
| Backend import error | Re-run poetry install in root |
| Port in use | Close previous dev servers or edit ports in scripts/launch_alphaforge.py |

After launch, submit a backtest from the UI; progress & results are powered by the running backend.


Note on architecture migration (2025-09-24): The repository has moved to a dual-root layout. Backend code now lives under `alphaforge-brain/src` with tests under `alphaforge-brain/tests`. A placeholder `alphaforge-mind/` root exists for future UI/visualization work. See `alphaforge-brain/ARCH_MIGRATION_STATUS.md` for exit criteria evidence and `ARCH_MIGRATION_RETROSPECTIVE.md` for lessons learned. An architecture diagram will be linked here in a future revision.

### Accessibility (Mind UI Early Baseline)
### Optimization Grid Defer Limit (AF_OPTIMIZATION_MAX_COMBINATIONS)
AlphaForge can detect very large walk-forward optimization grids and defer execution to protect interactive sessions. Set an environment variable to control the maximum allowed combinations:

PowerShell (Windows):
```powershell
$env:AF_OPTIMIZATION_MAX_COMBINATIONS=1000
```

Shell (Linux/macOS):
```bash
export AF_OPTIMIZATION_MAX_COMBINATIONS=1000
```

Behavior:
- If the product of parameter list lengths exceeds this limit, the backend returns `optimization_mode = "deferred"` in the run result.
- A structured warning appears under `advanced.warnings`:
  `{ code: "OPTIMIZATION_DEFERRED", combinations: <n>, limit: <limit> }`.
- Set to `0` (default) or unset to disable the limit and allow all grid sizes.

The emerging `alphaforge-mind` UI establishes an initial accessibility baseline (Tasks T092–T093):

| Aspect | Status | Notes |
|--------|--------|-------|
| Automated axe scan (BacktestValidationPage) | Passing (no critical violations) | Implemented via `jest-axe` + vitest. |
| Keyboard navigation (BacktestForm) | Passing | Tab order validated: start → end → strategy → equity → submit. |

During automated axe scans we enable a minimal rendering mode to reduce noise from complex charts and canvases:

```ts
(document.body as any).dataset.minA11y = 'true'; // set in axe test before render
```

When this flag is set, heavier visual/chart components and export modal are skipped, focusing the scan on semantic structure, headings, landmark regions, and form controls.

Current temporarily disabled axe rule(s):
- `region` – deferred until final landmark / sectional semantics are stabilized.

Future iterations will progressively enable stricter rules, add focus-visible styling audits, color contrast checks against theme tokens, and ARIA live region tests for async run status updates.

### Error Taxonomy, Structured Envelope, Correlation & UI Banner (Mind + Brain)
An initial UI-facing error taxonomy (T094) maps backend `detail` strings to stable descriptors (code, title, user message, severity). Implementation lives in `alphaforge-mind/src/errors/errorMessages.ts` and is covered by tests in `tests/integration/errorMapping.test.tsx`.

#### Structured Error Envelope (Backend T095 Enhancement)
All backend error responses (including plain `HTTPException`) are now normalized to:

```jsonc
{
  "detail": "rate limit exceeded",          // human-readable summary (legacy fastapi field)
  "error": {
    "code": "RATE_LIMIT",                  // stable machine-readable code (derived from detail today)
    "message": "rate limit exceeded",       // future-proof explicit message field
    "retryable": true                        // hint for UI (false for NOT_FOUND, validation errors, etc.)
  }
}
```

Headers are preserved/propagated from the originating exception (e.g. rate limit metadata). Existing clients that only inspect `detail` remain compatible while richer clients pivot to `error.code` / `error.retryable`.

#### Observability & Rate Limit Headers
Every response includes:
* `x-correlation-id` – supplied by client or generated middleware UUID (echoed back)
* `x-processing-time-ms` – integer elapsed wall-clock time for request handling
* `x-rate-limit-reset-after` (optional) – seconds until next Monte Carlo request token becomes available (only on HTTP 429)

Example 429 (abridged):
```http
HTTP/1.1 429 Too Many Requests
x-correlation-id: 6d7d5f0b-...-d2c0
x-rate-limit-reset-after: 7
content-type: application/json

{
  "detail": "rate limit exceeded",
  "error": {"code": "RATE_LIMIT", "message": "rate limit exceeded", "retryable": true}
}
```

#### UI Error Banner (Mind T096)
The Mind UI surfaces the latest error via a global `ErrorBanner` component which shows: severity styling, user-facing message, retry hint, correlation id, and a live countdown for rate limit resets.

Key pieces:
* State store: `alphaforge-mind/src/state/errors.ts` (Zustand) holds the active error.
* Fetch wrapper: `src/net/client.ts` injects correlation id & delegates non-2xx responses to `src/net/errors.ts` which parses the envelope, maps detail→descriptor, extracts headers, and populates the store.
* Banner component: `src/components/ErrorBanner.tsx` subscribes to the store, calculates remaining seconds until `rateLimitResetMs`, and updates once per second (inert when no countdown is present). Tested in `tests/components/ErrorBanner.test.tsx`.

Usage (Mind root layout):
```tsx
import ErrorBanner from './components/ErrorBanner.js';

export function AppShell() {
  return (
    <>
      <ErrorBanner />
      {/* rest of routes / pages */}
    </>
  );
}
```

Triggering logic requires no manual try/catch: any `afFetch()` call that returns `!resp.ok` will auto-populate the banner. To programmatically clear: `useErrorStore.getState().clear()`.

Countdown semantics: The banner treats `x-rate-limit-reset-after` as "soft wait" guidance; once the seconds reach zero the message flips to "You can retry now." (no automatic retry).

Tests providing assurance:
* Backend: `tests/test_rate_limit_metadata.py` (header propagation) & `tests/test_request_logging.py` (correlation structured log presence)
* UI: `tests/integration/errorMapping.test.tsx`, `tests/integration/correlationClient.test.ts`, `tests/components/ErrorBanner.test.tsx`

Planned follow-ups: backend will emit first-class `error.code` values directly (removing text inference), multi-error aggregation for batch validations, and opt-in verbose diagnostics gated by a query param or header.

#### Feature & Candle Cache Parquet Fallback
Both `CandleCache` and `FeaturesCache` now implement a resilient storage strategy that avoids a hard dependency on binary parquet wheels (pyarrow) in constrained or mismatched environments (e.g. NumPy 2.x installed while `pyarrow` wheel was compiled against 1.x). Key behaviors:

* Lazy detection: A small `_parquet_available()` helper attempts to import `pyarrow` at call time; failures (ImportError or binary incompatibility) transparently switch to CSV logic.
* Deterministic naming: Filenames always use a `.parquet` extension for stable test expectations and shard layout, even when the underlying bytes are CSV.
* Read fallback: If parquet parsing fails, a CSV parse is attempted against the same file path. Timestamp columns are re-normalized to UTC datetimes when present.
* Corruption heuristics: `FeaturesCache` validates presence of canonical candle columns; missing columns (e.g. after truncation) raise and trigger rebuild. CSV fallback writes guarantee file size changes so corruption tests continue to signal rebuild success.
* No configuration knobs: Behavior is automatic—installing a compatible `pyarrow` immediately upgrades persistence to true parquet without code changes.

Additional diagnostics & observability (follow‑up enhancement T097):

* One‑time structured log: The first time the system degrades to CSV mode a single log event is emitted: `{ "event": "cache_parquet_fallback", "reason": "pyarrow_unavailable" }` (reason may differ, e.g. `pyarrow_write_failed`). This prevents log noise while still surfacing environment capability.
* Doctor CLI: Run `python -m infra.cache.doctor --root <cache_dir>` to produce a JSON report summarizing parquet availability, detected `pyarrow` version (if any), aggregated in‑process cache metrics, and a classification of on‑disk cache files (`parquet` vs `csv_fallback`).

Example:
```powershell
poetry run python -m infra.cache.doctor --root .cache/candles | jq
```

Sample output (abridged):
```jsonc
{
  "files": [
    {"kind": "csv_fallback", "path": ".cache/candles/ab/SYM_null_null_deadbeef1234.parquet", "size": 842},
    {"kind": "parquet", "path": ".cache/candles/ff/SYM_null_null_f00ba7ef9912.parquet", "size": 4096}
  ],
  "metrics": {"hits": 12, "misses": 3, "rebuilds": 1, "writes": 3},
  "parquet_available": false,
  "pyarrow_version": null
}
```

Kinds are decided using the parquet magic header (`PAR1`) heuristic so inspection is O(1) per file. A non‑parquet file with a `.parquet` extension is treated as an intentional fallback, preserving deterministic naming.

Rationale: This keeps local iteration and CI green in heterogeneous Python/NumPy setups while still providing efficient columnar storage when the environment supports it. Future work may add a debug header or metrics counter to expose the active persistence mode.

| Category | Representative Detail | UI Code | Severity | User Message (abridged) |
|----------|-----------------------|---------|----------|--------------------------|
| Validation | `single symbol only (no comma separated list)` | SINGLE_SYMBOL_ONLY | error | Only one symbol can be backtested... |
| Validation | `invalid symbol format` | INVALID_SYMBOL | error | Unsupported characters... |
| Config | `invalid configuration:` (prefix) | INVALID_CONFIG_PREFIX | error | One or more configuration fields invalid... |
| Lookup | `run not found` | RUN_NOT_FOUND | error | Run could not be located... |
| Infra | `registry not initialized` | REGISTRY_UNAVAILABLE | warn | Registry not yet initialized... |
| Infra | `registry unavailable` | REGISTRY_UNAVAILABLE_ALT | error | Internal registry access failed... |
| Rate Limit | `rate limit exceeded` | RATE_LIMIT | warn | Too many Monte Carlo requests... |
| Listing | `limit must be positive` | INVALID_LIMIT | error | List request limit must be positive. |
| Artifact | `artifact not found` | ARTIFACT_NOT_FOUND | error | Artifact missing. |
| Artifact | `artifact unreadable` | ARTIFACT_UNREADABLE | error | Artifact corrupted/unreadable. |
| Range | `to must be >= from` | RANGE_INVALID | error | End date must not precede start. |
| Interval | `invalid interval` | INTERVAL_INVALID | error | Interval unsupported. |

Fallback: Any unmapped backend error → `UNKNOWN_ERROR` with generic remediation guidance.

Correlation IDs (T095): Every request passes through middleware that assigns or echoes an `x-correlation-id`. The Mind client wrapper (`src/net/client.ts`) injects a UUID if not provided and exposes a helper to read the echoed value. Backend integration test: `test_correlation_id.py`. Mind integration test: `correlationClient.test.ts`. This enables trace alignment across logs, network panels, and future structured telemetry.

Planned extensions: explicit machine-readable error codes in backend JSON (e.g. `{ "code": "INVALID_SYMBOL", "detail": "invalid symbol format" }`) to decouple UI taxonomy from raw text; redaction categorization; user-facing retry vs. abort classification.


---
## 1. Executive Overview
AlphaForge Brain executes an orchestrated pipeline: load candles → compute indicators/features → derive strategy signals → size positions (risk models) → simulate fills (slippage, fees, T+1) → compute metrics → perform validation (permutation, bootstrap, Monte Carlo, walk-forward) → assemble artifacts → emit ordered events (SSE) → persist manifest with integrity hash + chain linkage. Every run is **idempotent**: submitting the same canonical configuration returns the same `run_hash` and reuses existing artifacts.

**Why it exists:** To provide a trustworthy sandbox for researching and iterating on systematic strategies with strict reproducibility and transparent state transitions. It favors correctness, clarity, and traceable transformations over opaque monolith logic.

---
## 1.a Core Principles Summary (See full constitution: `.specify/memory/constitution.md`)
| # | Principle | Summary |
|---|-----------|---------|
| 1 | Deterministic Reproducibility | Same config + dataset snapshot → identical hash & artifacts; nondeterminism isolated or recorded. |
| 2 | Additive Contracts | Public schemas evolve additively; breaking changes require major version proposal. |
| 3 | Test-First Discipline | Failing tests precede implementation; all gates (mypy, ruff, pytest, spectral) must pass. |
| 4 | Data Integrity & Provenance | Validation summary + anomaly counters + data_hash surfaced; no silent imputation. |
| 5 | Modular Domain Architecture | Clear bounded contexts (data, features, strategy, risk, execution, validation, run). |
| 6 | Observability & Explainability | Structured logs + events enable post-hoc reasoning for every trade & anomaly. |
| 7 | Performance Guardrail | Measure first; optimize only with baseline + delta evidence. |
| 8 | Pragmatic Extensibility | Prepare only for upcoming multi-symbol/provider needs when non-breaking; avoid speculative layers. |
| 9 | Single Sources of Truth | One authoritative module per canonical dataset, registry, manifest hashing pipeline. |
| 10 | Automation as Policy | CI enforces all gates; manual checklists replaced by scripts. |

These principles drive design decisions, code review criteria, and release gating. Any deviation requires an explicit, time-bound exception documented in PR rationale.

---
## Runtime Requirements
Target runtime is pinned for determinism and reproducibility:

| Component | Requirement | Notes |
|-----------|-------------|-------|
| Python | 3.11.9 (>=3.11,<3.12) | Patch 9 selected for latest security/bug fixes while avoiding 3.12 semantics drift |
| Poetry | 1.8.x | Managed via CI (install-poetry action) |
| OS | Linux/macOS/Windows | CI runs on Ubuntu; Windows dev scripts provided (PowerShell) |
| Node.js (spec tooling) | 20.x | Used only for OpenAPI lint/bundle (Spectral + Redocly) |

Local setup (pyenv recommended):
```bash
pyenv install 3.11.9
pyenv local 3.11.9  # writes .python-version (already committed)
poetry env use 3.11.9
poetry install --with dev
```

Verification commands:
```bash
poetry run python --version  # Expect 3.11.9
poetry run mypy --version
node --version               # Expect v20.x
```

### Quick Poetry Setup (You Don’t Need To Manage Environments Manually)
If you are not comfortable managing Python environments, just follow these exact commands in PowerShell (Windows) or a shell (macOS/Linux):

PowerShell (Windows):
```powershell
# 1. Install Poetry (one time)
(Invoke-WebRequest -Uri https://install.python-poetry.org -UseBasicParsing).Content | py -

# 2. Ensure we're in the project root, then let Poetry create/use the virtualenv
cd C:\Users\amasr\AlphaForge3
poetry env use 3.11

# 3. Install dependencies (core + dev/test tools)
poetry install --with dev

# 4. Run a minimal sanity test (version guard)
poetry run pytest -k version_guard -q

# 5. Start the API server (press Ctrl+C to stop)
poetry run uvicorn api.app:app --reload
```

macOS / Linux:
```bash
curl -sSL https://install.python-poetry.org | python3 -
cd /path/to/AlphaForge3
poetry env use 3.11
poetry install --with dev
poetry run pytest -k version_guard -q
poetry run uvicorn api.app:app --reload
```

Optional extras:
```powershell
# Install optional performance or analytics extras
poetry install --with performance,analytics

# Install indicator pack (requires Python >= 3.12; skipped on 3.11 quietly)
poetry install --with indicators
```

Key points:
- You never activate the venv manually; always prefix commands with `poetry run`.
- If `poetry lock` asks to regenerate, run `poetry lock` then `poetry install` again.
- The indicator library `pandas-ta` is optional and only installs on Python 3.12+, so 3.11 users won’t get an error.

If something fails, copy the full error and open an issue/ask for help—don’t try to manually tweak the environment.

### Post-Install Health Check & Pre-Commit Hooks
After running `poetry install`, you can verify everything with:
```powershell
poetry run health-check
```
Expected output includes a JSON snippet from `/health` and `[HEALTH] Environment OK`.

To enable automatic quality and lockfile consistency checks before each commit:
```powershell
poetry run pre-commit install --install-hooks
```
Hooks added:
- ruff (auto-fix lint)
- black (format)
- env-check (ensures environment matches expectations)
- mypy-changed (type check only changed files)
- lock-sync (blocks commits that change pyproject.toml without poetry.lock)
- health-check (runs on pre-push to catch broken env before pushing)

To run all hooks manually:
```powershell
poetry run pre-commit run --all-files
```

---
## 1.b Runtime Version Introspection (API & CLI)
The FastAPI application version now dynamically reflects the `pyproject.toml` version (`0.3.0`) without manual edits to the app factory. This guarantees docs & `/health` stay synchronized after a version bump.

### Health Endpoint
Example response (abridged) from a local dev instance after starting via `uvicorn api.app:create_app` or equivalent helper:

```jsonc
{
  "status": "ok",
  "version": "0.3.0",
  "python": "3.11.9",
  "uptime_sec": 42,
  "build": "dev"
}
```

### PowerShell Example
```powershell
$resp = Invoke-RestMethod -Uri http://localhost:8000/health -Method GET
$resp.version  # Should output 0.3.0
```

### curl Example
```bash
curl -s http://localhost:8000/health | jq '.version'
# "0.3.0"
```

### 1.c Feature 006 Additive Versioned API (Mind Integration Preview)
Feature 006 introduces an additive, versioned surface under `/api/v1` powering the upcoming AlphaForge Mind UI. Legacy endpoints (`/runs`, `/backtest/run`) remain intact; no breaking removals. All new endpoints are deterministic and guarded by contract + integration tests.

| Method | Path | Purpose |
|--------|------|---------|
| GET | `/api/v1/market/candles` | Fetch candle slice for symbol/time window (pagination-ready) |
| POST | `/api/v1/backtests` | Submit (or reuse) a backtest run (returns `run_id`) |
| GET | `/api/v1/backtests/{run_id}` | Retrieve run result (equity, metrics, trades_summary, seed, strategy_hash) |
| POST | `/api/v1/backtests/{run_id}/montecarlo` | Deterministic Monte Carlo path fan + percentile curves (extended optional) |
| GET | `/api/v1/backtests/{run_id}/walkforward` | Walk-forward splits (deterministic placeholder scaffold) |
| GET | `/api/v1/backtests/{run_id}/config` | Canonical original request echo for reproducibility |
| GET | `/api/v1/backtests` | Recent run list (filterable) |

Key behaviors:
- Deterministic seeding: submission persists `seed` + lightweight `strategy_hash`; Monte Carlo precedence: request `seed` > stored run seed > derived.
- Extended percentiles: `extended_percentiles=true` adds `extended_percentiles.p5` & `p95` arrays alongside base curves.
- Advanced toggles passthrough: `extended_validation_toggles` / `advanced` objects accepted & echoed (reserved for future analytical modules).
- Observability middleware: adds `x-correlation-id` (client supplied or UUID v4) and `x-processing-time-ms` to every response.
- Rate limiting (guard rail): Simple in-memory token bucket for Monte Carlo endpoint (e.g., 8 calls / 10s per process) returns HTTP 429 on excess.

Example Monte Carlo request (PowerShell):
```powershell
$mc = '{"paths":50,"extended_percentiles":true,"seed":999}'
Invoke-RestMethod -Uri http://localhost:8000/api/v1/backtests/<RUN_ID>/montecarlo -Method POST -ContentType 'application/json' -Body $mc
```

curl variant:
```bash
curl -s -X POST http://localhost:8000/api/v1/backtests/<RUN_ID>/montecarlo \
  -H 'Content-Type: application/json' \
  -d '{"paths":50,"extended_percentiles":true,"seed":999}' | jq '.percentiles|keys'
```

Response excerpt (abridged):
```jsonc
{
  "paths": 50,
  "percentiles": {"p10": [...], "p50": [...], "p90": [...]},
  "extended_percentiles": {"p5": [...], "p95": [...]},
  "seed": 999,
  "run_id": "<RUN_ID>"
}
```

Determinism tests assert identical matrices & percentile arrays for identical seeds; rate limit tests ensure 429 surfaces without degrading subsequent valid calls.


### Programmatic Access Inside Code
```python
from api.app import create_app
app = create_app()
assert app.version == "0.3.0"
```

### How It Works
`create_app()` attempts `importlib.metadata.version("project-a-backend")`. If the distribution is not installed (editable dev mode), it parses `pyproject.toml` (`tool.poetry.version`) via `tomllib`. Fallback default is `0.0.0+dev` (should not appear in normal workflows). This ensures:
1. No drift between runtime and packaging metadata.
2. OpenAPI schema `info.version` matches the package.
3. Release automation only touches `pyproject.toml` (single source of truth).

### Dynamic Version Badge (JSON Endpoint)
CI generates a Shields.io compatible JSON endpoint via `scripts/ci/emit_version_badge.py`, producing `.artifacts/version_badge.json`. A lightweight publish job can push that file to a `badges` branch (served via GitHub Pages raw URL) powering the dynamic badge next to the static one. This ensures the README reflects the *current main branch version* even if a stale forked README is viewed. If the badge endpoint fails to load, the static badge still displays the last released version.

### Ingestion Baseline & Drift Classification
To guard determinism and silent data drift, the ingestion performance & structure are snapshotted:

1. Capture baseline (once or after intentional update):
  `poetry run python scripts/bench/capture_ingestion_baseline.py`
2. Store output at `benchmarks/baseline_ingestion_nvda_1d.json` (committed).
3. Generate current metrics in CI: `poetry run python scripts/bench/ingestion_perf.py --out-json current_ingestion.json`
4. Diff: `poetry run python scripts/bench/ingestion_baseline_diff.py benchmarks/baseline_ingestion_nvda_1d.json current_ingestion.json`

Exit codes:
| Code | Meaning | Action |
|------|---------|--------|
| 0 | PERFECT (structure + hash + elapsed) | Proceed |
| 20 | MINOR drift (elapsed only) | Log; optional performance review |
| 50 | BREAKING drift (row counts or data_hash changed) | Fail build; require explicit override justification |

Related provenance file: generated via `scripts/bench/generate_provenance.py` capturing source file hash & size for audit.

### Operational Notes
- CI smoke tests can assert `/health.version` equals the expected tag to catch accidental partial bumps.
- For pre-release identifiers (e.g. `0.3.0-rc.1`), the same mechanism surfaces the semver string unchanged.
- If you later adopt PEP 621 `project.version` (migrating from Poetry-specific table), the fallback parser can be adapted trivially.

---

If a different interpreter is detected in CI, the workflow will fail (version assertion step). This guards against silent upgrades to 3.12+ that could alter typing or performance characteristics.

---
## 2. Core Value Principles
| Principle | Meaning | Implementation Hooks |
|-----------|---------|----------------------|
| Determinism | Same input → same output (hash & artifacts) | Canonical JSON hashing, seeded validation, pure data transforms |
| Integrity | Artifacts tamper-evident | `manifest.json` + `manifest_hash` + `chain_prev` |
| Modularity | Swap / extend components easily | Registries (indicator, strategy, risk, slippage) |
| Observability | Understand progress & status | Ordered event buffer + SSE (flush & streaming) |
| Reproducibility | Full rerun without guessing | Config payload stored + lockfile + seed |
| Performance Insight | Measure, don’t assume | Microbenchmarks (`perf_run`, `risk_slippage`) |
| Safety & Clarity | No hidden randomness / side effects | Explicit seeds, no global mutable singletons (beyond controlled caches) |

---
## 3. High-Level Architecture
```
                +--------------------+
                |   Run Submission   |
                | (POST /runs)       |
                +---------+----------+
                          |
                    Hash & Idempotency
                          |
                  +-------v--------+
                  |  Orchestrator  |
                  +---+---+---+----+
                      |   |   |
        Data Layer <--+   |   +--> Event Buffer (ordered)
                      |   |         ^
      Feature / Indicators |         | SSE Flush / Stream
                      |   |         |
                 Strategy Runner     |
                      |             |
                  Risk Engine        |
                      |             |
               Execution Simulator   |
                      |             |
                   Metrics Calc      |
                      |             |
                  Validation Suite   |
                      |             |
                  Artifact Writer ---+
                      |
                 Manifest (hashed)
```
The orchestrator is a state machine that drives each stage deterministically. Each stage produces structured outputs that later phases consume, minimizing hidden coupling.

---
## 4. Full End-to-End Data Flow (Narrative Guide)
This section is your always-current mental model. Every run moves through the following exact phases. Each bullet contains 2–4 sentences to reinforce understanding.

1. Submission & Hashing: A client sends a `RunConfig` payload to `POST /runs`. The system canonicalizes (stable key ordering, normalized types) and hashes it with metadata (code version, seed). If a previous run with the same hash exists, the existing artifacts are reused and no recalculation occurs. This enables stateless retries and instant cache hits for deterministic experimentation.
2. Candle Loading & Caching: The data provider (currently local CSV/Parquet) loads the candle range, normalizes schema (timestamp, open/high/low/close/volume), and stores a cached Parquet slice keyed by its content hash. Subsequent identical data requests avoid re-loading overhead. Data immutability ensures downstream determinism.
3. Indicator & Feature Computation: Indicators (e.g., dual SMA) are computed over the candle frame with explicit lookback windows and no forward fill that causes lookahead bias. Features are cached similarly, keyed by both raw data hash and indicator parameters. This layer produces a feature matrix consumed by strategies.
4. Strategy Signal Generation: The strategy runner aligns indicator values and produces discrete position or signal states (e.g., long/flat toggles when fast/slow SMA cross). It deliberately avoids sizing decisions, producing only intent. This isolation allows reuse of signals across multiple risk model experiments.
5. Risk Sizing: Risk engine converts signals into position sizes via the selected model (`fixed_fraction`, `volatility_target`, `kelly_fraction`). Each implementation clamps output and uses stable historical statistics (e.g., realized volatility) for scaling. The result is a position series (desired target size per bar) ready for execution simulation.
6. Execution Simulation: The simulator walks through bars applying T+1 fills (signal at bar N executed at bar N+1 open or chosen price proxy). Slippage models (none, `spread_pct`, `participation_rate`) and fee/slippage basis points adjust fill prices deterministically. Edge cases like zero volume or end-of-range flattening are handled explicitly to avoid orphaned state.
7. Trade & State Tracking: As fills occur, trades are instantiated, and portfolio state (cash, position, equity curve) is updated. The engine ensures chronological consistency and prevents impossible negative fill conditions. Intermediate states are not mutated retroactively, preserving auditability.
8. Metrics Computation: Returns, drawdowns, Sharpe-like ratio, and other summary statistics derive from the equity curve and trade list. All metrics functions are pure: they accept immutable structures and return new aggregates. This encourages independent revalidation or extension.
9. Validation Suite: Statistical modules (permutation, bootstrap, Monte Carlo, walk-forward) run using deterministic seeds derived from the base seed plus indexed offsets. Outputs (p-values, confidence intervals, partition summaries) become structured validation artifacts. This phase does not alter prior artifacts—only appends results.
10. Artifact Assembly & Manifest: The artifact writer compiles metrics, trades, validation outputs, and run configuration references. A `manifest.json` with `manifest_hash` plus `chain_prev` (linking to the prior run’s manifest hash) provides integrity chaining. Any tampering or partial deletion becomes detectable when reconstructing the chain.
11. Event Buffering & Emission: Each phase emits events (e.g., `started`, `data_loaded`, `features_ready`, `strategy_done`, `risk_done`, `execution_done`, `metrics_done`, `validation_done`, `artifacts_finalized`, `completed`). These are stored in an ordered in-memory buffer with stable incremental IDs. Clients either poll via flush endpoint (with `ETag` caching) or attach a long-lived streaming SSE connection for incremental push.
12. Completion & Reuse: Once the terminal event is emitted, the run enters a stable state. Re-submitting identical configuration yields the same hash and returns immediately referencing existing artifacts (no recomputation). This drastically shortens iterative parameter tuning cycles.

### ASCII Sequence (Abbreviated)
```
Client -> API (/runs) -> Orchestrator
Orchestrator -> Data Provider -> Cache
Orchestrator -> Indicator Engine -> Feature Cache
Orchestrator -> Strategy Runner
Orchestrator -> Risk Engine
Orchestrator -> Execution Simulator
Orchestrator -> Metrics Calculator
Orchestrator -> Validation Suite
Orchestrator -> Artifact Writer -> Manifest
Orchestrator -> Event Buffer -> (SSE Stream / Flush)
Client <- SSE: progress ... terminal
```

---
## 5. Domain Components
### Indicators
Each indicator registers via a decorator into the indicator registry. Parameters are validated and serialized for caching keys. Adding a new indicator requires a pure function returning a pandas Series/DataFrame aligned to input index.

### Strategies
Strategies transform aligned indicator outputs into target exposure signals. They do not execute trades or size positions. This keeps them testable and cheap to iterate.

### Risk Models
Risk models translate exposure intent into position sizing. `volatility_target` scales the base fraction inversely with realized volatility; `kelly_fraction` applies a conservative Kelly sizing formula dampened by a base fraction. All models clamp sizes to valid ranges and are side-effect free.

### Slippage Models
Slippage adapters transform theoretical execution price before costs: `spread_pct` shifts by half-spread; `participation_rate` applies impact proportional to order participation in bar volume. They run before fee and generic BPS slippage adjustment, keeping ordering explicit and auditable.

### Execution Simulator
Applies T+1 logic, zero-volume guards, and produces trade records and state deltas. Determinism is maintained by avoiding random partial fills or latency modeling in this scope.

### Metrics & Validation
Metrics compute time-series and aggregate performance figures. Validation modules assess robustness: permutation tests re-randomize signal structure; bootstrap resamples segments; Monte Carlo perturbs distributions; walk-forward splits evaluate temporal generalization.

### Artifacts & Manifest
Artifacts (metrics, trades, validation summaries) are written to disk. A manifest consolidates pointers, sizes, and hashes. `chain_prev` links prior manifest to build a verifiable lineage.

---
## 6. Events & Streaming

The system emits ordered Server-Sent Events (SSE) for run progress. Baseline synchronous runs emit a heartbeat + snapshot, with additive future stages planned (async orchestration, cancellation propagation). See `tests/api/test_run_events_*` for expected sequences.

---
## 7. NVDA Dataset Quickstart & Deterministic Helper (T041–T042)

An integrated 5-year NVDA dataset powers provenance + anomaly demonstrations. A PowerShell helper script provides a zero-setup canonical run invocation and prints key artifact paths plus anomaly counters.

Quickstart (Windows PowerShell):
```powershell
pwsh ./scripts/run_local_nvda.ps1 -Start 2024-01-01 -End 2024-01-10 -Output run_detail.json
```

Example output excerpts:
```
[NVDA] Submitting deterministic run (NVDA 2024-01-01->2024-01-10 tf=1m)
Run hash: 4f0c2e9...
Artifacts: artifacts/4f0c2e9...
Manifest: artifacts/4f0c2e9.../manifest.json
Anomaly counters: {"duplicates_dropped":0,"rows_dropped_missing":3,...}
```

Determinism Guarantees:
- Re-running with identical dataset + parameters reuses hash & artifacts.
- Editing the underlying CSV (single price) invalidates the run hash (perturbation test T039).
- `_dataset` provenance (symbol, timeframe, data_hash) is namespaced inside the hash input to avoid collision with user config fields.

To surface anomaly counters in API responses, pass `include_anomalies=true` to `GET /runs/{hash}`.

Planned (T044+): golden baseline snapshot & ingestion baseline diff gating in CI for structural drift detection.

---
Two modes:
1. Flush Endpoint: `GET /runs/{run_hash}/events` returns all events (optionally filtered with `after_id`). ETag header `<run_hash>:<last_event_id>` allows 304 responses if no new events.
2. Streaming Endpoint: `GET /runs/{run_hash}/events/stream` replays backlog then waits for new events, sending periodic heartbeat events (~15s) until terminal.

Event Schema (conceptual):
```json
{
  "run_hash": "string",
  "id": 7,
  "ts": "2025-09-20T12:34:56.789Z",
  "type": "metrics_done",
  "payload": {"metrics": {"sharpe": 1.23}}
}
```
Clients can recover from disconnect by supplying `Last-Event-ID` (stream) or `after_id` (flush).

---
## 7. Determinism & Reproducibility
Determinism rests on canonical configuration serialization, stable seeded flows, and absence of nondeterministic IO. Run hash = SHA-256 over canonical JSON (sorted keys, normalized types) plus version metadata. Validation modules derive sub-seeds from the base seed using indexed offsets (ensuring independence yet reproducibility). Manifest chaining allows verifying no retroactive mutation across historical runs.

Reproduce Checklist:
1. Same code & `poetry.lock`.
2. Original JSON payload (include `seed`).
3. Same environment variables (if any feature flags introduced later).
4. Submit via `/runs`; identical `run_hash` indicates reuse.
5. Fetch artifacts; verify manifest hash & `chain_prev` alignment.

### 7.a Deterministic Testing Infrastructure (2025-09-23 refresh)

Recent hardening introduced a unified layer ensuring tests asserting time, randomness, and structural segmentation remain fully reproducible:

| Concern | Mechanism | Location | Notes |
|---------|-----------|----------|-------|
| Wall-clock timestamps | `freeze_time` fixture replaces module-level `datetime` class with subclass overriding `now()/utcnow()` | `tests/conftest.py` | Avoids mutating CPython built-in; patches only project modules so third-party libs unaffected. |
| Random permutations / bootstrap | Central `random_seed_fixture` seeds `random` and feeds explicit seed args to engines | `tests/conftest.py` & permutation tests | Eliminates ad-hoc seeding scattered across tests. |
| Walk-forward segmentation variance | Parameterized tests derive expected segment counts algorithmically | `tests/unit/test_walk_forward_splits.py` | Edge case of insufficient bars (< train+test) explicitly allowed to return zero segments. |
| Object creation boilerplate | Factory helpers for configs & models | `tests/factories.py` | Ensures consistent defaults (timezone-aware datetimes) & reduces duplication. |
| Timezone correctness | All runtime datetimes use `datetime.now(timezone.utc)` | throughout models/services | Legacy `utcnow()` calls removed; fixtures align with aware datetimes. |

Benefits:
* Zero flake baseline—any failure now indicates a regression rather than incidental timing drift.
* Reduced test verbosity; factories encapsulate canonical defaults (dataset snapshot, execution, cost, validation config, etc.).
* Clear extension pattern: new validation module only needs deterministic seed derivation + factory hook.

Guidelines for Contributors:
1. Do not call `datetime.now()` or `datetime.utcnow()` directly in tests—rely on model defaults or request `freeze_time` if you must assert exact instants.
2. For new randomness-dependent logic, accept an explicit `seed: int | None` argument (do not read global state inside the function).
3. Add parametric coverage (small/edge/typical) rather than multiple near-duplicate test functions.
4. When asserting collections with hashes or timestamps, prefer full equality if fixture-provided; avoid prefix / substring unless intentionally focusing format.
5. If a test needs true variability, document why deterministic seeding would hide a class of bugs and add a comment `# nondeterministic-by-design`.

Future Enhancements (not yet implemented):
* Global fixture for numpy / pandas random seeding (currently deterministic paths do not depend on their RNGs).
* Snapshot-based artifact schema diffing (augmenting contract tests) to catch unapproved field additions.

---
## 7.c Mypy Strictness & Typing Quality Policy (2025-09)

The project runs mypy in effectively "strict" mode (see `mypy.ini`) across all first‑party modules. Goals of the policy:

1. Prevent silent runtime bugs (attribute typos, Optional misuse, incorrect container element assumptions).
2. Keep ignore debt visible and bounded; every `# type: ignore[...]` must be justified or removed within the same feature branch unless explicitly grandfathered.
3. Treat typing regressions like failing tests—no net new errors on main.

### Configuration Highlights (`mypy.ini`)
Key enabled flags (abridged):
- disallow_incomplete_defs = True
- disallow_untyped_defs = True
- disallow_untyped_calls = True
- disallow_any_generics = True
- warn_unused_ignores = True
- warn_redundant_casts = True
- warn_return_any = True
- strict_optional = True

### Allowances
| Scenario | Allowed? | Rationale / Guidance |
|----------|----------|----------------------|
| Broad `# type: ignore` without code owner comment | ❌ | Must narrow to specific code(s) or refactor. |
| Optional dependency imports (`structlog`, `jsonschema`) | ✅ (wrapped) | Wrapped in `try/except`; no ignore unless attribute genuinely missing at type level. |
| Protocol fallbacks / dynamic monkeypatch (pandas shift) | ✅ | Kept minimal; no blanket ignores after refactor. |
| Runtime-only test monkeypatch compatibility (`get_dataset_metadata`) | ✅ | Guarded by `TYPE_CHECKING` and stable placeholder class. |

### CI Gate (Delta Enforcement)
CI compares current typing error count against a persisted baseline artifact (`mypy_baseline.txt`). A build fails if:
* New errors are introduced (count increases), or
* Any previously ignored error category resurfaces after being driven to zero (e.g. `unused-ignore`).

When refactors eliminate existing baseline errors, update the baseline file in the same PR to ratchet the standard upward. Never edit the baseline to hide new errors.

### Adding New Code
Checklist for a new module:
1. No untyped function definitions.
2. All public return values precisely typed (avoid `Any`).
3. Guard imports for optional deps with `try/except` instead of `# type: ignore`.
4. Prefer `TypedDict` / `dataclass` / Pydantic models over loose `dict[str, Any]` where shape is stable.
5. Run `poetry run mypy path/to/module.py` locally before committing.

### Justifying an Ignore
Use the format: `# type: ignore[specific-code]  # reason: <short justification>`
Accepted short reasons: `3rd_party_missing_typing`, `false_positive`, `protocol_variance`, `pending_refactor`.
Remove the ignore in the same PR if you fix the underlying cause.

### Developer Tips
* Prefer narrowing with `isinstance` / local guards instead of casting.
* For DataFrame/Series heavy code, isolate dynamically typed transformations in small helper functions to minimize `Any` spread.
* Use `cast()` only at module boundaries (IO, cache load) where runtime invariants are externally enforced.

### Reporting
Artifacts produced by CI:
- `mypy_final.txt`: Full report after PR changes.
- `mypy_diff.md`: Human-friendly summary (added, removed, remaining categories).
- `typing_timing.json/md`: Timing diagnostics to spot pathological modules.

If a timing spike >3x prior average appears, open an issue tagging `#typing-perf` for investigation (often caused by large union expansion or recursive generics).

---


---
## 7.b Robustness & Validation
This system embeds a multi-layer statistical validation framework so performance claims are contextualized rather than cherry‑picked:

| Component | Purpose | Determinism Hook |
|-----------|---------|------------------|
| Permutation Test | Break temporal signal structure to estimate null distribution of performance | Seeded structural shuffles (stable seed list derived from base seed) |
| Bootstrap Resample (planned) | Resample segments to quantify sampling variability | Deterministic segment index generation |
| Monte Carlo (planned) | Perturb returns or fills for distributional stress | Seeded RNG & fixed perturbation policy |
| Walk-Forward Segmentation | Evaluate OOS stability across rolling windows | Segment boundaries computed algorithmically (size, stride, warmup) |
| Robustness Score | Composite of p_value (permutation), tail behavior, OOS consistency | Pure function of deterministic components |

Key Guarantees:
1. Validation modules never mutate primary artifacts (metrics, trades); they only append structured results.
2. All randomness sources accept explicit seeds; sub-seeds use `base_seed + offset` for stable trial ordering.
3. The permutation engine preserves gap structure (no synthetic timestamps) preventing temporal compression artifacts.
4. Walk-forward segmentation yields deterministic non-overlapping windows or zero segments—never ambiguous partials.
5. `robustness_score` is recomputable at any time from manifest-linked inputs; no hidden mutable state.

Interpreting Outputs:
- `p_value`: Probability under the null (randomized structure) of observing a result at least as extreme.
- `extreme_tail_ratio`: Realized performance / high quantile of null distribution (guards against overstated small p-values).
- `oos_consistency_score`: Stability of out-of-sample segment returns.
- `robustness_score`: Weighted aggregate balancing evidence strength & OOS stability.

Usage Pattern:
1. Run a deterministic baseline with small permutation trial count.
2. Inspect `validation.json` (permutation distribution, summary fields).
3. Scale trials (e.g., 30 → 100) only if early evidence warrants.
4. Add walk-forward config to measure OOS degradation once base logic stable.
5. Track `robustness_score` deltas rather than raw Sharpe to avoid variance noise.

Anti-Patterns Avoided:
- No p-hacking loops (trial count fixed per run).
- No adaptive early stopping biasing p-values.
- No mutation of fill/trade series during validation phases.

Planned (Next Minor): bootstrap & Monte Carlo modules—schema additions remain additive.

See `specs/003-elevate-project-a/research.md` and upcoming `docs/architecture/truthful_run.md` for deeper rationale.


---
## 8. Risk & Slippage Model Usage
Example risk config (volatility target):
```json
"risk": {"model": "volatility_target", "params": {"base_fraction": 0.2, "target_vol": 0.15, "lookback": 30}}
```
Kelly variant:
```json
"risk": {"model": "kelly_fraction", "params": {"base_fraction": 0.1, "win_prob": 0.55, "reward_risk": 1.4}}
```
Slippage example:
```json
"execution": {"slippage_model": "participation_rate", "params": {"participation_pct": 0.1}, "slippage_bps": 4, "fee_bps": 1.2}
```

---
## 9. API Guide (Practical Quickstart)
| Action | Endpoint | Method | Notes |
|--------|----------|--------|-------|
| Create run | `/runs` | POST | Returns `run_hash` (idempotent) |
| List runs | `/runs` | GET | Sorted recent (retention window) |
| Run detail | `/runs/{run_hash}` | GET | Includes status & manifest link |
| Artifacts | `/runs/{run_hash}/artifacts` | GET | Manifest, metrics, validation references |
| Events (flush) | `/runs/{run_hash}/events` | GET | ETag + `after_id` support |
| Events (stream) | `/runs/{run_hash}/events/stream` | GET | SSE incremental |
| Presets CRUD | `/presets` | POST/GET/DELETE | Idempotent create by (name, config) |

Minimal run creation (PowerShell):
```powershell
$body = '{
  "symbol": "TEST", "timeframe": "1m", "start": "2024-01-01", "end": "2024-01-02",
  "indicators": [{"name":"sma","params":{"window":5}},{"name":"sma","params":{"window":15}}],
  "strategy": {"name":"dual_sma","params":{"fast":5,"slow":15}},
  "risk": {"model":"fixed_fraction","params":{"fraction":0.1}},
  "execution": {"slippage_bps":0,"fee_bps":0},
  "validation": {"permutation": {"trials": 3}},
  "seed": 42
}'
Invoke-RestMethod -Method POST -Uri http://localhost:8000/runs -ContentType 'application/json' -Body $body
```

---
## 10. Presets Workflow
Presets wrap frequently used configurations. Creating identical (name, config) returns the existing `preset_id` (no duplication or conflict errors). Backed by JSON file or SQLite index depending on environment variable selection. This optimizes iterative UI flows where a user tweaks only one parameter between runs.

---
## 11. Benchmarks & Performance Instrumentation
Two complementary harnesses:
- End-to-End (`scripts/bench/perf_run.py`): Measures orchestration latency, trade counts, summary stats.
- Micro (`scripts/bench/risk_slippage.py`): Isolates per-model call overhead for risk sizing & slippage transforms.

Run examples:
```powershell
poetry run python scripts/bench/perf_run.py --iterations 5 --warmup 1
poetry run python scripts/bench/risk_slippage.py --iterations 300 --risk-models fixed_fraction,volatility_target,kelly_fraction --slippage none,spread_pct,participation_rate
```

---
## 12. Repository Layout
```
src/
  api/                # FastAPI app & routes
  domain/             # Core domain logic (strategy, risk, execution, validation, artifacts)
  infra/              # Config, logging, db, utilities
scripts/
  bench/              # Performance & microbench harnesses
  dev/                # Developer helpers
specs/                # Architecture, plan, openapi, research
presets/              # Stored presets (if not overridden)
```

---
## 12.a NVDA Dataset Placement (Group 1 Foundation)
For the NVDA 5‑Year integration feature the ingestion layer expects a canonical CSV file at:

```
./data/NVDA_5y.csv
```

Required columns (case-sensitive):
`timestamp,open,high,low,close,volume` (optional: `adj_close` ignored)

Normalization assumptions:
- Source timezone: America/New_York (converted to UTC epoch ms `ts`)
- Daily timeframe; gaps classified via exchange-calendars (NYSE schedule proxy)
- Duplicate timestamps: keep first, drop rest (counter incremented)
- Missing critical fields: row dropped
- Zero volume: retained with `zero_volume=1`
- Future dated rows (ts > now UTC): dropped

Deterministic dataset hash (`data_hash`) is computed over canonical columns:
`ts,open,high,low,close,volume,zero_volume` with stable float formatting and ordering.

If you need a different location, set up or symlink `data/` accordingly before running Group 2+ tasks.


---
## 13. Extensibility Guide
### Add an Indicator
1. Implement a pure function returning a pandas Series.
2. Decorate with the registry decorator specifying name & parameter schema.
3. Add unit test ensuring no lookahead (shift checks) and window correctness.

### Add a Strategy
1. Define parameter schema.
2. Consume indicator outputs → produce discrete signal states (e.g., -1/0/1 or boolean transitions).
3. Test over a small synthetic frame with deterministic expectations.

### Add a Risk Model
1. Implement sizing function taking position intent and price history (if needed).
2. Enforce clamping & deterministic math (no random draws).
3. Register in risk engine switch; add tests for monotonic scaling.

### Add a Slippage Adapter
1. Accept trade direction, quantity, bar volume/price context.
2. Produce adjusted price; keep side-effect free.
3. Register & test impact vs baseline.

### Add Validation Method
1. Accept deterministic seeds; derive sub-seeds from base.
2. Return structured result schema (summary + any detail arrays).
3. Add reproducibility test ensuring identical outputs with same config.

---
## 14. Local Development & Quality Gates
Install & Run:
```powershell
poetry install --with dev
poetry run uvicorn api.app:app --host 0.0.0.0 --port 8000 --reload
```
Quality Gates:
```powershell
poetry run pytest --disable-warnings -q
poetry run mypy src
poetry run ruff check .
```
Zero warnings are tolerated (CI treats warnings as errors). Type & lint gates must be green before merging changes.

Note on pytest-asyncio: defaults are pinned to silence deprecation warnings. See `pytest.ini`:
```
asyncio_mode = auto
asyncio_default_fixture_loop_scope = function
```

Dev Script Helper:
```powershell
pwsh scripts/dev/run_api.ps1 -Port 8000 -Reload
```

---
### 14.a Typing & Lint Guarantees (Added in upcoming 0.3.0)
The repository enforces a zero-regression typing and lint contract:
| Guarantee | Enforcement Mechanism |
|-----------|-----------------------|
| mypy strict (src + tests) zero errors | CI snapshot gate (`.mypy_snapshot_src.json`) + diff report (`mypy_diff.md`) |
| No stale `# type: ignore` | `warn-unused-ignores` + periodic audit (G22 complete) |
| Modern syntax only (PEP 604, builtin generics) | Ruff + mypy; legacy patterns rejected |
| Selective fast feedback in commits | Pre-commit hook: changed-file mypy strict |

---
## 15. Retention Enhancements: Cold Storage Offload, Restore & Plan Diff

Recent additions extend the retention system beyond local demotion to support optional cold storage offload (S3, GCS, or local mirror), restoration, and configuration diffs.

### 15.1 Cold Storage Overview
When `AF_COLD_STORAGE_ENABLED=1` the system can offload demoted run artifacts to an external object store, retaining only the manifest and a small `cold_manifest.json` pointer locally. This reduces disk usage while preserving recoverability.

Environment variables:
| Var | Purpose | Example |
|-----|---------|---------|
| `AF_COLD_STORAGE_ENABLED` | Master switch ("1" to enable) | `1` |
| `AF_COLD_STORAGE_PROVIDER` | `s3`, `gcs`, or `local` (mirror) | `s3` |
| `AF_COLD_STORAGE_BUCKET` | Target bucket (s3/gcs) | `my-af-backups` |
| `AF_COLD_STORAGE_PREFIX` | Optional key prefix | `prod` |

Providers:
* `local`: Stores tarballs under `artifacts/cold-mirror/` (testing & dev).
* `s3`: Requires `boto3` (install via `poetry install -E storage`); credentials pulled from standard AWS chain.
* `gcs`: Requires `google-cloud-storage` (also `-E storage`); application default credentials or explicit service account.

Offload Flow:
1. Retention apply demotes a run (moves artifacts to `.evicted`).
2. `infra.cold_storage.offload` tars & gzips evicted files, uploads single object `runs/<run_hash>/<ts>.tar.gz`.
3. Writes `cold_manifest.json` with object key, size, file list.
4. Deletes local copies (manifest retained). Failure is silent (retention integrity prioritized).

Restore Flow (`POST /runs/{run_hash}/restore`):
1. If run is `manifest-only`, attempts cold restore first.
2. Downloads tarball, extracts missing files, updates manifest with `restored_at` timestamp.
3. Falls back to local rehydrate (from `.evicted`) if cold restore not available.

### 15.2 Retention Plan Diff Endpoint
`POST /retention/plan/diff` accepts partial overrides (`keep_last`, `top_k_per_strategy`, `max_full_bytes`) and returns:
```jsonc
{
  "current": {"kept": 40, "demoted": 60},
  "alternative": {"kept": 55, "demoted": 45, "config": {"keep_last": 60}},
  "diff": {"new_demotions": ["hashA"], "new_full": ["hashB"], "lost_full": ["hashA"]}
}
```
Use this to simulate retention tuning without mutating state or writing audit events.

### 15.3 Audit Rotation & Compression Metrics
`GET /retention/metrics` now includes `audit_rotation`:
```jsonc
"audit_rotation": {
  "rotation_count": 2,
  "rotated_original_bytes": 123456,
  "rotated_compressed_bytes": 45678,
  "compression_ratio": 0.37
}
```
Absent or zero rotations → empty object (field present for forward-compatible contract). Compression ratio omitted (null) if no bytes yet rotated.

### 15.4 Enabling Storage Extras
Install optional providers:
```powershell
poetry install -E storage
```
This brings in `boto3` and `google-cloud-storage` without bloating the core runtime for users who do not need remote offload.

### 15.5 Failure Semantics
* Any exception during offload or restore is swallowed (best-effort) and logged via simple prints (future: structured logging hook) to avoid blocking retention.
* Manifest absence during restore → graceful noop.
* Partial extraction leaves successfully restored files; subsequent restore attempts skip already present files.

### 15.6 Future Hardening Ideas
* Integrity hash of tarball stored in manifest for end-to-end verification.
* Streaming multipart upload for very large artifacts.
* Background worker queue for asynchronous offload to remove latency from retention apply path.
* Per-run encryption via KMS-managed data keys.

---
| Lint regression prevention | Expanded Ruff rules (bugbear, pyupgrade strict) |
| Performance visibility of typing stage | Timing benchmark artifact (`typing_timing.json/md`) |

If a new mypy error appears in a PR, the diff report highlights the delta and CI fails. This ensures steady-state zero-error baseline.

---
## SDK Quickstart (AlphaForge Mind Client)

Use the lightweight Python client to submit and inspect runs without hand-crafting HTTP calls.

Install (editable develop if not packaged yet):
```powershell
poetry install --with dev
```

Example:
```python
from alphaforge_mind_client import AlphaForgeMindClient  # if exposed as distribution entry
# Or: from client import AlphaForgeMindClient (when running from repo root with PYTHONPATH set)

client = AlphaForgeMindClient(base_url="http://localhost:8000")
config = {
  "symbol": "TEST", "timeframe": "1m",
  "start": "2024-01-01", "end": "2024-01-02",
  "indicators": [
    {"name": "sma", "params": {"window": 5}},
    {"name": "sma", "params": {"window": 15}},
  ],
  "strategy": {"name": "dual_sma", "params": {"fast": 5, "slow": 15}},
  "risk": {"model": "fixed_fraction", "params": {"fraction": 0.1}},
  "execution": {"slippage_bps": 0, "fee_bps": 0},
  "validation": {},
  "seed": 42,
}

sub = client.submit_run(config)
print("Run hash:", sub.run_hash, "created?", sub.created)
detail = client.get_run(sub.run_hash)
print("Status:", detail["status"])
artifacts = client.list_artifacts(sub.run_hash)
print("Artifacts count:", len(artifacts))

# Retention plan diff (what if we raised keep_last?)
diff = client.diff_retention_plan(keep_last=75)
print("Retention diff new_full:", diff.get("diff", {}).get("new_full"))

# Restore (noop if already full)
client.restore(sub.run_hash)
```

Determinism check: Re-submit `config` → `created` should be False and `run_hash` identical.

---
## Troubleshooting Hello Run

| Symptom | Likely Cause | Resolution |
|---------|--------------|------------|
| 404 /runs or 422 validation error | Missing field or JSON structure mismatch | Compare payload to OpenAPI (`openapi.html`); ensure required keys (`symbol`, `timeframe`, `start`, `end`, `indicators`, `strategy`, `risk`, `execution`, `seed`). |
| 500 on submit | Underlying migration/schema mismatch | Re-run with fresh SQLite or apply migrations (check CI migrations head script). |
| Immediate different run_hash after minor edit | Hash includes dataset/version metadata | Confirm you didn't alter dataset slice; check logs for dataset hash changes. |
| No events streaming / stuck | Using flush endpoint only | Use `/runs/{hash}/events/stream` SSE or loop flush with `after_id`. |
| Retention restore returns noop | Run not demoted or cold storage disabled | Confirm `retention_state` is `manifest-only` and `AF_COLD_STORAGE_ENABLED=1`. |
| Contract drift gate failing locally | Regeneration script path / PYTHONPATH not set | Run inside Poetry: `poetry run python scripts/ci/run_quality_gates.py`. |
| Memory cap gate skip | Non-Linux platform | Accept (skip) or run in a Linux container to enforce. |
| OpenAPI mismatch in client usage | Cached schema or stale server | Regenerate spec (`npm run deref:api`) and restart server. |

If unresolved, inspect `zz_artifacts/` for recent gate summaries and determinism replay outputs.

## 15. Troubleshooting & FAQ
| Symptom | Cause | Resolution |
|---------|-------|-----------|
| Docker build slow | Cold dependency layer | Re-run; subsequent builds leverage cache layers |
| Re-run not recomputing | Idempotent hash hit | Change a config field (e.g., seed) to force recompute |
| Streaming idle | No new events | Heartbeats every ~15s confirm liveness |
| Different hash after pull | Dependency drift | Reinstall with lockfile; ensure no uncommitted changes |
| Validation timing large | High trials count | Reduce `permutation.trials` or bootstrap sample size |

Virtualization Checks (Windows):
```powershell
pwsh scripts/env/check_virtualization.ps1 -Json virt_report.json
```
`virt_report.json` is a local-only artifact and is ignored by git.

---
## 16. Roadmap (Indicative)
- Additional indicators (momentum, volatility clustering)
- Portfolio-level multi-symbol extension (registry now prepared)
- Advanced execution (queue modeling, partial fills)
- Coverage badge publication (Codecov)
- WebSocket multiplex (evaluation vs SSE)
- Enhanced validation visualization support
- Dataset diff tooling & ingestion provenance explorer

### 16.a Upcoming 0.3.0 Highlights (Unreleased)
- Multi-symbol dataset abstraction & canonical slice registry.
- Typing hardening (strict + modernization + diff gating).
- Lint rule expansion & automated diff/timing artifacts.
- Strengthened run hash semantics including dataset binding.
- Zero remaining ignores; baseline codified.

---
## 17. License
MIT License – see `LICENSE` (if not present, add before external distribution).

---
## 18. Acknowledgements
Developed with a focus on small, test-first increments and explicit contracts. Inspired by practical needs of systematic strategy research and reproducibility discipline.

---
## Hello Run (Quickstart)

For a concise end‑to‑end deterministic run walkthrough (submission → events → artifacts → re-run reuse) see `specs/005-refine-alphaforge-brain/quickstart.md`.

Key links:
- Latest OpenAPI (dereferenced): `openapi.deref.json` (generated in CI) – also browsable via bundled `openapi.html`.
- Implementation Plan: `specs/005-refine-alphaforge-brain/plan.md`
- Data Model: `specs/005-refine-alphaforge-brain/data-model.md` (if present) – describes tables & indices referenced by persistence layer.
- Retention & Cold Storage details: [Section 15](#15-retention-enhancements-cold-storage-offload-restore--plan-diff)

Core determinism contract:
1. Stable canonical JSON hashing of run config (sorted keys, normalized numeric/text forms)
2. Seed derivation tree (base seed → validation sub-seeds)
3. Dataset binding via content hash ensures input mutation invalidates prior hash
4. Idempotent re-submission returns identical `run_hash` & reuses artifacts

### Minimal Local Run
```powershell
poetry install --with dev
poetry run uvicorn api.app:app --reload
# Submit
curl -X POST http://localhost:8000/runs -H "Content-Type: application/json" -d '{"symbol":"TEST","timeframe":"1m","start":"2024-01-01","end":"2024-01-02","indicators":[{"name":"sma","params":{"window":5}},{"name":"sma","params":{"window":15}}],"strategy":{"name":"dual_sma","params":{"fast":5,"slow":15}},"risk":{"model":"fixed_fraction","params":{"fraction":0.1}},"execution":{"slippage_bps":0,"fee_bps":0},"validation":{},"seed":42}'
```

After completion, re-run the same payload; the response should be immediate referencing existing artifacts (cache reuse). For deeper explanation (events streaming, permutations, retention pin/unpin) consult the extended quickstart document.

**Quick Start Recap**
```powershell
poetry install --with dev
poetry run uvicorn api.app:app --reload
# Submit a run
curl -X POST http://localhost:8000/runs -H "Content-Type: application/json" -d '{"symbol":"TEST","timeframe":"1m","start":"2024-01-01","end":"2024-01-02","indicators":[{"name":"sma","params":{"window":5}},{"name":"sma","params":{"window":15}}],"strategy":{"name":"dual_sma","params":{"fast":5,"slow":15}},"risk":{"model":"fixed_fraction","params":{"fraction":0.1}},"execution":{"slippage_bps":0,"fee_bps":0},"validation":{},"seed":42}'
```

> Keep this README as a living contract: update Data Flow & Extensibility sections first when architecture evolves.

## Persistence (Run → Query)
AlphaForge Brain records each run’s inputs and results in a small, file‑based database (SQLite). You can:
- Inspect high‑level run info (manifest, seeds, version)
- Review the equity curve and list of trades
- Check validation summaries and timing markers

Start here for a friendly walkthrough: `specs/004-alphaforge-brain-refinement/persistence-quickstart.md`.

## Validation: Bootstrap and Walk‑Forward
To check that results are reliable, the system runs statistical validations:
- Bootstrap (with HADJ‑BB block selection and deterministic seeds)
- Walk‑forward (performance across rolling time windows)

Learn the policies and plain‑language background:
- Contracts appendix: `specs/004-alphaforge-brain-refinement/contracts-appendix.md`
- HADJ‑BB & CI Width Policy: `specs/004-alphaforge-brain-refinement/hadj-bb-ci-width-policy.md`

## Chunk Mode: Memory‑Friendly Feature Building
Feature construction can run in chunks to reduce memory usage while preserving correctness and determinism. This mode uses overlapping windows to avoid any peek into the future.

## Architecture Overview
A high‑level diagram that shows how pieces fit together is available at:
- `specs/004-alphaforge-brain-refinement/architecture-diagram.md`
